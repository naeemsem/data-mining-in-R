{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Transaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, our team will be doing a Kaggle challenge on Santander’s data set. Santander is a Spanish owned financial bank, and they need help with identifying customer behavior and spending habit. We will be using their provided data set to bring a solution to their problem. We believe this data set can be a great practice to apply what we have been learning in the class, such as classification and prediction methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project description/Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a dataset from Kaggle based on the challenge. Kaggle is hosting for Santander bank. On the overview page Kaggle has outlined this description:\n",
    "At Santander, our mission is to help people and businesses prosper. We are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals.\n",
    "Our data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan?\n",
    "In this challenge, we will identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle competition Santander Customer Transaction Prediction dataset containing 200 numeric feature variables, the binary “target” column, and a string “ID_code” column. The training set is 200000 records which may require some dimension reduction in order to be more computationally efficient and to classify more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'MASS' is in use and will not be installed\"Warning message:\n",
      "\"package 'ggplot2' is in use and will not be installed\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'data.table' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"cannot remove prior installation of package 'data.table'\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Naeem\\AppData\\Local\\Temp\\Rtmp6jpX05\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"MASS\", repos = \"http://cran.us.r-project.org\")\n",
    "install.packages(\"ggplot2\", repos = \"http://cran.us.r-project.org\")\n",
    "install.packages(\"data.table\", repos = \"http://cran.us.r-project.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(data.table): there is no package called 'data.table'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(data.table): there is no package called 'data.table'\nTraceback:\n",
      "1. library(data.table)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(MASS)\n",
    "library(ggplot2)\n",
    "library(data.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the dimension of train and test sets. Also check what are the variables that are there in train but not in test. Also let's have a look at the head of the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in fread(\"train.csv\"): could not find function \"fread\"\n",
     "output_type": "error",
     "traceback": [
      "Error in fread(\"train.csv\"): could not find function \"fread\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "train = fread(\"train.csv\")\n",
    "dim(train) ; dim(test) ; setdiff(colnames(train) , colnames(test)) ; head(train) ; head(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It seems like the variables have no names as such and the only variable that is missing in the test set is the target column which we need to predict.\n",
    "We need target column in both train set and test set so I will use train set only in this case.\n",
    "Let's remove the ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in train$ID_code = NULL: object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in train$ID_code = NULL: object 'train' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "train$ID_code = NULL\n",
    "\n",
    "str(train)\n",
    "\n",
    "# datasets are too big. let's keep the first 21 variables\n",
    "# train <- train[,1:22]\n",
    "# str(train)\n",
    "# test <- test[,1:21]\n",
    "# str(test)\n",
    "summary(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are NA or blank values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in apply(train, 2, NaValue): object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in apply(train, 2, NaValue): object 'train' not found\nTraceback:\n",
      "1. apply(train, 2, NaValue)"
     ]
    }
   ],
   "source": [
    "NaValue = function (x) {sum(is.na(x)) }\n",
    "apply(train, 2, NaValue)\n",
    "# no NAs\n",
    "BlankValue = function (x) {sum(x==\"\") }\n",
    "apply(train, 2, BlankValue)\n",
    "# no blanks\n",
    "dataset <- train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset is ready for model. At a first step, I split into train set and test set. The data is split into 60-40 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nrow(dataset): object 'dataset' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in nrow(dataset): object 'dataset' not found\nTraceback:\n",
      "1. sample(1:nrow(dataset), 0.6 * nrow(dataset))",
      "2. nrow(dataset)"
     ]
    }
   ],
   "source": [
    "set.seed(1)\n",
    "row.number = sample(1:nrow(dataset), 0.6*nrow(dataset))\n",
    "train = dataset[row.number,]\n",
    "test = dataset[-row.number,]\n",
    "dim(train)\n",
    "dim(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in attach(train): object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in attach(train): object 'train' not found\nTraceback:\n",
      "1. attach(train)"
     ]
    }
   ],
   "source": [
    "attach(train)\n",
    "model1 = glm(factor(target)~., data=train, family=binomial)\n",
    "summary(model1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial model shows most variables are statistically siginificant.\n",
    "\n",
    "Predict for training data and find training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.prob = predict(model1, type=\"response\")\n",
    "pred.prob = ifelse(pred.prob > 0.5, 1, 0) # I use 0.5 as default threshold. should we change it to lower?\n",
    "table(pred.prob, target)\n",
    "# the accuracy of the model is 0.9145583=(106456+3291)/120000\n",
    "detach(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in attach(test): object 'test' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in attach(test): object 'test' not found\nTraceback:\n",
      "1. attach(test)"
     ]
    }
   ],
   "source": [
    "attach(test)\n",
    "pred.prob = predict(model1, newdata= test, type=\"response\")\n",
    "pred.prob = ifelse(pred.prob > 0.5, 1, 0)\n",
    "table(pred.prob, target)\n",
    "# the accuracy of the model is 0.9139125=(70943+2170)/80000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in attach(train): object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in attach(train): object 'train' not found\nTraceback:\n",
      "1. attach(train)"
     ]
    }
   ],
   "source": [
    "attach(train)\n",
    "lda.model = lda (factor(target)~., data=train)\n",
    "lda.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in predict(lda.model, data = train): object 'lda.model' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in predict(lda.model, data = train): object 'lda.model' not found\nTraceback:\n",
      "1. predict(lda.model, data = train)"
     ]
    }
   ],
   "source": [
    "predmodel.train.lda = predict(lda.model, data=train)\n",
    "table(Predicted=predmodel.train.lda$class, target=train$target)\n",
    "# accuracy =0.914625=(106361+3394)/120000 very similar to logisitc regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "The below plot shows how the response class has been classified by the LDA classifier. \n",
    "The X-axis shows the value of line defined by the co-efficient of linear discriminant for LDA model. \n",
    "The two groups are the groups for response classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ldahist(predmodel.train.lda$x[, 1], g = predmodel.train.lda$class): object 'predmodel.train.lda' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in ldahist(predmodel.train.lda$x[, 1], g = predmodel.train.lda$class): object 'predmodel.train.lda' not found\nTraceback:\n",
      "1. ldahist(predmodel.train.lda$x[, 1], g = predmodel.train.lda$class)"
     ]
    }
   ],
   "source": [
    "ldahist(predmodel.train.lda$x[,1], g= predmodel.train.lda$class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, Group 0 has normal distribution. However, Group 1 does not have normal distribution. \n",
    "So, LDA is probably not ideal to predict because one of its preliminary is both groups should be normal distribution with same covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in attach(test): object 'test' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in attach(test): object 'test' not found\nTraceback:\n",
      "1. attach(test)"
     ]
    }
   ],
   "source": [
    "# check accuracy for test data\n",
    "attach(test)\n",
    "predmodel.test.lda = predict(lda.model, newdata=test)\n",
    "table(Predicted=predmodel.test.lda$class, target=test$target)\n",
    "# accuracy is 0.9140625 = (70891+2234)/80000 slightly lower than logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in plot(predmodel.test.lda$x[, 1], predmodel.test.lda$class, col = test$target + : object 'predmodel.test.lda' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in plot(predmodel.test.lda$x[, 1], predmodel.test.lda$class, col = test$target + : object 'predmodel.test.lda' not found\nTraceback:\n",
      "1. plot(predmodel.test.lda$x[, 1], predmodel.test.lda$class, col = test$target + \n .     10)"
     ]
    }
   ],
   "source": [
    "par(mfrow=c(1,1))\n",
    "plot(predmodel.test.lda$x[,1], predmodel.test.lda$class, col=test$target+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA model\n",
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in attach(train): object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in attach(train): object 'train' not found\nTraceback:\n",
      "1. attach(train)"
     ]
    }
   ],
   "source": [
    "attach(train)\n",
    "qda.model = qda(factor(target)~., data=train)\n",
    "qda.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predmodel.train.qda = predict(qda.model, data=train)\n",
    "table(Predicted=predmodel.train.qda$class, target=target)\n",
    "# accuracy = 0.939325 = (106068+6651)/120000 much better than logistic regression and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in attach(test): object 'test' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in attach(test): object 'test' not found\nTraceback:\n",
      "1. attach(test)"
     ]
    }
   ],
   "source": [
    "attach(test)\n",
    "predmodel.test.qda = predict(qda.model, newdata=test)\n",
    "table(Predicted=predmodel.test.qda$class, target=test$target)\n",
    "# accuracy = 0.9076625=(70390+2223)/80000 accuracy is lower in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in plot(predmodel.test.qda$posterior[, 2], predmodel.test.qda$class, : object 'predmodel.test.qda' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in plot(predmodel.test.qda$posterior[, 2], predmodel.test.qda$class, : object 'predmodel.test.qda' not found\nTraceback:\n",
      "1. plot(predmodel.test.qda$posterior[, 2], predmodel.test.qda$class, \n .     col = test$target + 10)"
     ]
    }
   ],
   "source": [
    "par(mfrow=c(1,1))\n",
    "plot(predmodel.test.qda$posterior[,2], predmodel.test.qda$class, col=test$target+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDA has more incorrect classifications.\n",
    "It seems logitstic regression is the best classifier among the 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in as.data.frame(test[, 1:10]): object 'test' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in as.data.frame(test[, 1:10]): object 'test' not found\nTraceback:\n",
      "1. as.data.frame(test[, 1:10])"
     ]
    }
   ],
   "source": [
    "data <- as.data.frame(test[,1:10])\n",
    "\n",
    "hist(data$var_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is short for e***X***treme ***G***radient ***Boost***ing package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is an algorithm that has recently been dominating applied machine learning and Kaggle competitions for large structured data.\n",
    "XGBoost is an implementation of gradient boosted decision trees designed for speed and performance. Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/tutorials/model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(data.table): there is no package called 'data.table'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(data.table): there is no package called 'data.table'\nTraceback:\n",
      "1. library(data.table)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(data.table)\n",
    "library(caret)\n",
    "library(xgboost)\n",
    "library(pROC)\n",
    "train = fread(\"../santander-customer-transaction-prediction/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $obj (\\theta) = \\sum_{i=1}^n L(y_i,y_i^t) +\\sum_{i=1}^t \\omega(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "### $Logloss = -1/N \\sum_{i=1}^N[y_i log p_i + (1-y_i)log(1-p_i)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above equation, N is the number of instances or samples. ‘yi’ would be the outcome of the i-th instance. Let us say, there are two results that an instance can assume, for example, 0 and 1. In the above equation, ‘yi’ would be 1 and hence, ‘1-yi’ is 0. ‘pi’ indicates the probability of the i-th instance assuming the value ‘yi’. In other words, log loss cumulates the probability of a sample assuming both states 0 and 1 over the total number of the instances. The simple condition behind the equation is: For the true output (yi) the probabilistic factor is -log(probability of true output) and for the other output is -log(1-probability of true output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularization term controls the complexity of the model, which helps us to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\omega(\\theta) = \\gamma T +1/2 \\lambda \\sum_{j=1}^T w_j^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here w is the vector of scores on leaves, T is the number of leaves, and \\lambda is a shrinkage factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in train$ID_code = NULL: object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in train$ID_code = NULL: object 'train' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Let's remove the ID column\n",
    "\n",
    "train$ID_code = NULL\n",
    "test$ID_code = NULL\n",
    "\n",
    "target = train$target\n",
    "summary(target)\n",
    "table(target)\n",
    "\n",
    "# we have 10% of the labels as positive and rest are zeros. Now let's create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in createFolds(factor(target), k = 5, list = FALSE): could not find function \"createFolds\"\n",
     "output_type": "error",
     "traceback": [
      "Error in createFolds(factor(target), k = 5, list = FALSE): could not find function \"createFolds\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "nrounds = 5\n",
    "set.seed(1234)\n",
    "folds = createFolds(factor(target), k = 5, list = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nrow(train): object 'train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in nrow(train): object 'train' not found\nTraceback:\n",
      "1. nrow(train)"
     ]
    }
   ],
   "source": [
    "dev.result <-  rep(0, nrow(train)) \n",
    "pred_te <- rep(0, nrow(test))\n",
    "\n",
    "for (this.round in 1:nrounds) {      \n",
    "  valid <- c(1:length(target)) [folds == this.round]\n",
    "  dev <- c(1:length(target)) [folds != this.round]\n",
    "  \n",
    "  dtrain<- xgb.DMatrix(data= as.matrix(train[dev,]), \n",
    "                       label= target[dev])\n",
    "  #weight = w[dev])\n",
    "  dvalid <- xgb.DMatrix(data= as.matrix(train[valid,]) , \n",
    "                        label= target[valid])\n",
    "  valids <- list(val = dvalid)\n",
    "  #### parameters are far from being optimal ####  \n",
    "  param = list(objective = \"binary:logistic\", \n",
    "               eval_metric = \"auc\",\n",
    "               max_depth = 4,\n",
    "               eta = 0.05,\n",
    "               gamma = 5,\n",
    "               subsample = 0.7,   \n",
    "               colsample_bytree = 0.7,\n",
    "               min_child_weight = 50,  \n",
    "               colsample_bylevel = 0.7,\n",
    "               lambda = 1, \n",
    "               alpha = 0,\n",
    "               booster = \"gbtree\",\n",
    "               silent = 0\n",
    "  ) \n",
    "  model<- xgb.train(data = dtrain,\n",
    "                    params= param, \n",
    "                    nrounds = 5000, \n",
    "                    verbose = T, \n",
    "                    list(val1=dtrain , val2 = dvalid) ,       \n",
    "                    early_stopping_rounds = 50 , \n",
    "                    print_every_n = 500,\n",
    "                    maximize = T\n",
    "  )\n",
    "  pred = predict(model,as.matrix(train[valid,]))\n",
    "  dev.result[valid] = pred  \n",
    "  pred_test  = predict(model,tefinal)\n",
    "  pred_te = pred_te +pred_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the xgboost CV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in auc(target, dev.result): could not find function \"auc\"\n",
     "output_type": "error",
     "traceback": [
      "Error in auc(target, dev.result): could not find function \"auc\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "auc(target,dev.result)\n",
    "pred_test = pred_te/nrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
